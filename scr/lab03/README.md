# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3: –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞

## –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–π

### 1. normalize(text)
- –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: —É–¥–∞–ª—è–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
- –ó–∞–º–µ–Ω—è–µ—Ç –±—É–∫–≤—É "—ë" –Ω–∞ "–µ"
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É

```python
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –ø—É—Ç–µ–º —É–¥–∞–ª–µ–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É.
    
    –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:
    - –£–¥–∞–ª—è–µ—Ç —Å–∏–º–≤–æ–ª—ã —Ç–∞–±—É–ª—è—Ü–∏–∏ (\t) –∏ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏ (\n)
    - –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã (–≤ –Ω–∞—á–∞–ª–µ, –∫–æ–Ω—Ü–µ –∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏)
    - –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º casefold()
    - –ó–∞–º–µ–Ω—è–µ—Ç –±—É–∫–≤—É '—ë' –Ω–∞ '–µ' (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Examples:
        normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t") == "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"
        normalize("—ë–∂–∏–∫, –Å–ª–∫–∞") == "–µ–∂–∏–∫, –µ–ª–∫–∞"
    """

    if not isinstance(text, str):
        raise ValueError("normalize: text –Ω–µ str")
    
    if len(text) == 0:
        raise ValueError("normalize: –ø—É—Å—Ç–æ–π text")

    result = (((text.replace("\t"," ")).replace("\r"," ")).replace("\n"," "))
    result = " ".join((result.strip()).split())

    if casefold:
        result = result.casefold()

    if yo2e:
        result = result.replace('—ë', '–µ')

    return result
```

### 2. tokenize(text)  
- –†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞ (—Ç–æ–∫–µ–Ω—ã)
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ-–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ª–æ–≤–∞ —Å –¥–µ—Ñ–∏—Å–∞–º–∏

```python
def tokenize(text: str) -> list[str]:
    """
    –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–¥–µ–ª—è–µ—Ç –≤—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É –Ω–∞ —á–∞—Å—Ç–∏, –∏—Å–ø–æ–ª—å–∑—É—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
    –ª—é–±—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –±—É–∫–≤–∞–º–∏ –∏–ª–∏ —Ü–∏—Ñ—Ä–∞–º–∏.

    Examples:
        tokenize("–ø—Ä–∏–≤–µ—Ç, –º–∏—Ä!") == ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]
        tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ") == ["–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É", "–∫—Ä—É—Ç–æ"]
        tokenize("2025 –≥–æ–¥") == ["2025", "–≥–æ–¥"]
    """
    import re

    if not isinstance(text, str):
        raise ValueError("tokenize: text –Ω–µ str")
    
    if len(text) == 0:
        raise ValueError("tokenize: –ø—É—Å—Ç–æ–π text")
    
    split_result = re.split(r"[^\w-]+", text)
    
    return [item for item in split_result if len(item) >= 1]
```

### 3. count_freq(tokens)
- –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {—Å–ª–æ–≤–æ: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ}

```python
def count_freq(tokens: list[str]) -> dict[str, int]:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Å–ª–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Ç–æ–∫–µ–Ω–æ–≤.

    Examples:
        count_freq(["a","b","a","c","b","a"]) == {"a":3, "b":2, "c":1}
        count_freq(["bb","aa","bb","aa","cc"]) == {"aa":2, "bb":2, "cc":1}
    """
    from collections import Counter

    if not isinstance(tokens, list):
        raise ValueError("tokenize: text –Ω–µ str")
    
    if len(tokens) == 0:
        raise ValueError("count_freq: –ø—É—Å—Ç–æ–π tokens")

    return dict(sorted(dict(Counter(tokens)).items(), key=lambda item: (-item[1], item[0])))
```

### 4. top_n(freq, n)
- –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ - –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É

```python
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø-N —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã.

    Examples:
        top_n({"a":3, "b":2, "c":1}, 2) == [("a",3), ("b",2)]
        top_n({"aa":2, "bb":2, "cc":1}, 2) == [("aa",2), ("bb",2)]
    """

    if not isinstance(freq, dict):
        raise ValueError("top_n: freq –Ω–µ  dict")
    
    if len(freq) == 0:
        raise ValueError("top_n: –ø—É—Å—Ç–æ–π freq")
    
    return sorted(freq.items(), key=lambda item: (-item[1], item[0]))[:n]
```

## –¢–µ—Å—Ç-–∫–µ–π—Å—ã

### in
```python
try:
    print("normalize")
    print("–¢–µ—Å—Ç 1:", normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
    print("–¢–µ—Å—Ç 2:", normalize("—ë–∂–∏–∫, –Å–ª–∫–∞", yo2e=True))
    print("–¢–µ—Å—Ç 3:", normalize("Hello\r\nWorld"))
    print("–¢–µ—Å—Ç 4:", normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))

    print("\ntokenize")
    print("–¢–µ—Å—Ç 1:", tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
    print("–¢–µ—Å—Ç 2:", tokenize("hello,world!!!"))
    print("–¢–µ—Å—Ç 3:", tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
    print("–¢–µ—Å—Ç 4:", tokenize("2025 –≥–æ–¥"))
    print("–¢–µ—Å—Ç 5:", tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

    print("\ncount_freq + top_n")
    print("–¢–µ—Å—Ç 1(count_freq):", count_freq(["a","b","a","c","b","a"]))
    print("–¢–µ—Å—Ç 2(top_n):", top_n(count_freq(["a","b","a","c","b","a"]), n=2))
    print("–¢–µ—Å—Ç 3(count_freq):", count_freq(["bb","aa","bb","aa","cc"]))
    print("–¢–µ—Å—Ç 4(top_n):", top_n(count_freq(["bb","aa","bb","aa","cc"]), n=2))
except ValueError as e:
    print(f"–û—à–∏–±–∫–∞: {e}")
```

### out
![–ó–∞–¥–∞–Ω–∏–µ B‚òÖ](../../images/lab03/img01.png)

## –ó–∞–¥–∞–Ω–∏–µ B‚òÖ - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞

### –û–ø–∏—Å–∞–Ω–∏–µ
–°–æ–∑–¥–∞–Ω–∞ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è:
- –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –µ–≥–æ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `normalize()`
- –†–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Ç–æ–∫–µ–Ω—ã —Å –ø–æ–º–æ—â—å—é `tokenize()`
- –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É —Å–ª–æ–≤ —á–µ—Ä–µ–∑ `count_freq()`
- –í—ã–≤–æ–¥–∏—Ç —Ç–æ–ø-5 —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤ –≤ –≤–∏–¥–µ –∫—Ä–∞—Å–∏–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã

### –ö–æ–¥ –ø—Ä–æ–≥—Ä–∞–º–º—ã
```python
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from lib.text import *

def print_table(words_data: list[tuple[str, int]]) -> None:
    """
    –í—ã–≤–æ–¥–∏—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å–ª–æ–≤ –∏ –∏—Ö —á–∞—Å—Ç–æ—Ç –≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ.
    
    –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Å–ª–æ–≤–æ, —á–∞—Å—Ç–æ—Ç–∞) –∏ –≤—ã–≤–æ–¥–∏—Ç –∏—Ö –≤ –≤–∏–¥–µ
    —á–∏—Ç–∞–µ–º–æ–π —Ç–∞–±–ª–∏—Ü—ã —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º –∫–æ–ª–æ–Ω–æ–∫. –®–∏—Ä–∏–Ω–∞ –ø–µ—Ä–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ —Å–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –≤ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–µ.
    """
    if not words_data:
        raise ValueError("print_table: words_data –ø—É—Å—Ç")
    
    max_word_length = max(len(word) for word, count in words_data)

    if len("—Å–ª–æ–≤–æ") > max_word_length:
        max_word_length = len("—Å–ª–æ–≤–æ")
    
    print(f"{'—Å–ª–æ–≤–æ':<{max_word_length}} | —á–∞—Å—Ç–æ—Ç–∞")
    print("-" * max_word_length + "-|-" + "-" * 7)
    
    for word, count in words_data:
        print(f"{word:<{max_word_length}} | {count}")

try:
    inpt_text = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç: ")
    normalize_text = normalize(inpt_text)
    tokens = tokenize(normalize_text)
    freq = count_freq(tokens)
    top_words = top_n(freq, 5)

    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(freq)}")

    print("–¢–æ–ø-5:")
    print_table(top_words)

except ValueError as e:
    print(f"–û—à–∏–±–∫–∞: {e}")
```

### –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
![–ó–∞–¥–∞–Ω–∏–µ B‚òÖ - –†–µ–∑—É–ª—å—Ç–∞—Ç](../../images/lab03/img02.png)

## –ê–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥—ã

### –ß—Ç–æ –±—ã–ª–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ:
1. **–§—É–Ω–∫—Ü–∏—è `normalize()`** - —É—Å–ø–µ—à–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç, —É–±–∏—Ä–∞—è –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥—è –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
2. **–§—É–Ω–∫—Ü–∏—è `tokenize()`** - –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–ª–æ–≤–∞ —Å –¥–µ—Ñ–∏—Å–∞–º–∏
3. **–§—É–Ω–∫—Ü–∏—è `count_freq()`** - —Ç–æ—á–Ω–æ –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—É —Å–ª–æ–≤ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–æ —É–±—ã–≤–∞–Ω–∏—é
4. **–§—É–Ω–∫—Ü–∏—è `top_n()`** - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–º—ã—Ö —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤
5. **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞** - —Å–æ–∑–¥–∞–µ—Ç —É–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞

### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
- –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–º–µ—é—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã–¥–∞—é—Ç –ø–æ–Ω—è—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `casefold()` –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
- –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: `r"[^\w-]+"`
  - `r` - raw string (—Å—ã—Ä–∞—è —Å—Ç—Ä–æ–∫–∞), –æ—Ç–∫–ª—é—á–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (`\n`,`\t` –∏ –¥—Ä—É–≥–∏–µ)
  - `[^\w-]` - —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —è–≤–ª—è—é—Ç—Å—è –±—É–∫–≤–∞–º–∏, —Ü–∏—Ñ—Ä–∞–º–∏, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º –∏–ª–∏ –¥–µ—Ñ–∏—Å–æ–º
  - `+` - –æ–¥–∏–Ω –∏–ª–∏ –±–æ–ª–µ–µ —Ç–∞–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø–æ–¥—Ä—è–¥
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –∏–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π: `sys.path.append(os.path.join(os.path.dirname(__file__), '..'))`
  - `sys.path.append()` - –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—É—Ç—å –∫ —Å–ø–∏—Å–∫—É –ø—É—Ç–µ–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–æ–¥—É–ª–µ–π
  - `os.path.dirname(__file__)` - –ø–æ–ª—É—á–∞–µ—Ç –ø–∞–ø–∫—É —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
  - `os.path.join(..., '..')` - –ø–æ–¥–Ω–∏–º–∞–µ—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø–∞–ø–∫–µ `lib`
  - –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ `lib.text` –º–æ–¥—É–ª—è
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –≤ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º–µ

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:
- –í—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–æ–≤–µ—Ä–µ–Ω–∞ —Ä–∞–±–æ—Ç–∞ —Å –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏ –∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö